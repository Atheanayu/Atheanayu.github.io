<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <meta name="theme-color" content="#3367D6"/>
  <link rel="apple-touch-icon" href="/icons-192.png">
  <link rel="manifest" href="/manifest.json">
  
  <meta name="generator" content="Hexo 6.0.0">

  

  

  
    <meta name="author" content="Han Yu">
  

  

  

  <title>RNN | Han</title>

  

  
    <link rel="shortcut icon" href="/favicon.ico">
  

  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@1.1.3/index.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlightjs@9.16.2/styles/monokai.css">
  

  
<link rel="stylesheet" href="/css/style.css">

</head>
<body>
  <div class="root-container">
    
<!-- header container -->
<header class="header-container post">
  
    <div class="post-image" style="background-image: url(//user-images.githubusercontent.com/15166794/39033684-3053546e-44ae-11e8-893a-7fa685039ce2.png)"></div>
  

  <!-- navbar -->
<nav class="navbar">
  <div class="navbar-content">
    <!-- logo -->
    <div class="navbar-logo">
      <a href="/">
        
          Han
        
      </a>
    </div>
    <!-- link -->
    <div class="navbar-link">
      <div class="navbar-btn">
        <div></div>
        <div></div>
        <div></div>
      </div>
      <ul class="navbar-list">
        
          <li class="navbar-list-item"><a href="/">首页</a></li>
        
          <li class="navbar-list-item"><a href="/links">友链</a></li>
        
          <li class="navbar-list-item"><a href="/about">关于</a></li>
        
      </ul>
    </div>
  </div>
</nav>

  
  

  
  

  
  

  
  

  
  
    <div class="header-content">
      <div class="post-text layout-block">
        <div class="layout-margin">
          <h1 class="title-wrap">RNN</h1>
          <h2 class="title-sub-wrap">
            <strong>Han Yu</strong>
            <span>发布于</span>
            <time  class="article-date" datetime="2022-01-07T06:40:16.000Z" itemprop="datePublished">2022-01-07</time>
          </h2>
          <ul class="wrap-list dark">
  
    <li><a href="/categories/BasicModels/">📒 BasicModels</a></li>
  
</ul>
          <ul class="wrap-list dark">
  
    <li><a href="/tags/basic/">🏷️ basic</a></li>
  
</ul>
        </div>
      </div>
    </div>
  

  
  
  
</header>

    <!-- 文章 -->

<!-- 文章内容 -->
<div class="body-container">
  <article class="content-container layout-block post-container">
    <div class="article-info">
      
      
      
      
      <section class="article-entry markdown-body layout-margin content-padding--large soft-size--large soft-style--box">
        <!-- toc -->

<ul>
<li><a href="#cnn">CNN</a></li>
<li><a href="#rnn">RNN</a></li>
<li><a href="#lstm">LSTM</a></li>
<li><a href="#variants-on-lstm">VARIANTS ON LSTM</a><ul>
<li><a href="#peephole-version">PEEPHOLE VERSION</a></li>
<li><a href="#shared-gate">SHARED GATE</a></li>
<li><a href="#gru%E5%BE%85%E8%A1%A5%E5%85%85">GRU(待补充)</a></li>
</ul>
</li>
<li><a href="#bilstm">BILSTM</a></li>
<li><a href="#transformer">TRANSFORMER</a><ul>
<li><a href="#encoder">ENCODER</a></li>
<li><a href="#self-attention">SELF-ATTENTION</a></li>
<li><a href="#residuals">RESIDUALS</a></li>
<li><a href="#decoder">DECODER</a></li>
</ul>
</li>
<li><a href="#self-regression">Self Regression</a></li>
</ul>
<!-- tocstop -->

<h1><span id="cnn">CNN</span></h1><p>特点：参数共享</p>
<p>引入卷积核的原因在于全连接层所需的参数太多容易过拟合</p>
<p><strong>卷积的作用</strong></p>
<p>​        卷积核对应图片之中的感受野，卷积上的权重表现了图片不同位置的focus。</p>
<p>​        sobel算子：[[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]] 可以检测水平梯度，也就是检测纵向边缘。而[[-1, -2, -1], [0, 0, 0], [1, 2, 1]] 可以检测纵向梯度，也就是横向边缘。</p>
<p><strong>小卷积核 vs 大卷积核</strong></p>
<p>​        多个小卷积核可以起到一个大卷积核的作用。比如2个3x3的卷积核和1个5x5的卷积核可以起到相同的作用。而2x9x9 &lt; 5 * 5 因此采用多个小卷积核可以起到减少参数，防止过拟合的作用。</p>
<p><strong>Dropout</strong></p>
<p>​        每次输入都有一定概率删除部分神经元，以此防止过拟合。</p>
<p><strong>Pooling</strong></p>
<p>​        max pooling: 得到纹理信息</p>
<p>​        avg pooling: 得到背景信息</p>
<p><strong>BN层</strong></p>
<p>​        batch normalization</p>
<p>​        加速收敛</p>
<p><strong>全连接层</strong></p>
<p>​        将输出变成一维向量</p>
<p>​        存在问题：参数多容易过拟合</p>
<h1><span id="rnn">RNN</span></h1><p>循环神经网络。为了让模型有记忆。</p>
<p><img src="/2022/01/07/RNN/img-1.jpg" alt="img"></p>
<p>以上的图片展示了RNN的基本思路。</p>
<p>其中左半部分中的循环层一旦去掉，模型则退化成为了一个基本的神经网络模型。</p>
<p>循环层则是连接了前一轮和当前的隐藏层。</p>
<p>V – 输入层到隐藏层的权重</p>
<p>U – 隐藏层到输出层的权重</p>
<p>W – 前一轮隐藏层到当前隐藏层的权重</p>
<p>更具体来讲，RNN模型可以看做如下：</p>
<p><img src="/2022/01/07/RNN/img-2.jpg" alt="img"></p>
<p>前一张图里的X，S，O均为向量。</p>
<p>后一张图中的每个单元则表示一个单独的值。</p>
<p>因此可见，隐藏层的当前状态有两个决定因素：当前的输入和前一个时间片的隐藏层的状态（记忆）。</p>
<h1><span id="lstm">LSTM</span></h1><p>RNN 的示意图如下：</p>
<p><img src="/2022/01/07/RNN/img-3.png" alt="img"></p>
<p>RNN理论上可以记忆先前从输入中获取的知识，但是由于记忆没有选择性，因此只能记忆比较短的内容。当面对长句子时候，RNN模型不能够很好的处理。</p>
<p>因此需要一种模型可以抓住关键信息。LSTM是RNN的一种变体，可以学习到long-term dependencies。</p>
<p>RNN单元内部具体操作，如下：</p>
<p><img src="/2022/01/07/RNN/img-5.png" alt="img"></p>
<p>也就是在RNN部分的  中，f为tanh。</p>
<p>tanh为常见的激活函数，曲线和sigmoid有类似之处，但是相比sigmoid存在的梯度消失问题，tanh有所缓解。</p>
<p>RNN中的tanh主要是在模型中引入非线性。</p>
<p>相比起RNN，LSTM的内部模块更加复杂：</p>
<p><img src="/2022/01/07/RNN/img-6.png" alt="img"></p>
<p>其中：</p>
<p><img src="/2022/01/07/RNN/img-7.png" alt="img"></p>
<p>每一个时间点上的状态叫做<strong>cell state</strong></p>
<p>LSTM的基本思想为：<strong>忘记该忘记的，记住该记住的</strong></p>
<p>首先是如下这条线路：</p>
<p><img src="/2022/01/07/RNN/img-8.png" alt="img"></p>
<p>这表示前一个cell state如果没有做任何的选择，也没有加入当前cell state的输入内容的话，就会直接传递给下一个cell state</p>
<p>因为我们需要先遗忘一部分不重要的东西，因此先通过遗忘门：</p>
<p><img src="/2022/01/07/RNN/img-9.png" alt="img"></p>
<p>这里的  是一个介于0到1之间的向量，用于描述记下来多少信息。</p>
<p>先将  和  拼接成一个更大的向量，然后用  （权重矩阵）与它们相乘 — 空间映射，将原本的向量映射到与 相同，同时向量中的每一个元素都包含了  和  的全部信息。实际上该操作与  完全相同。</p>
<p>加上一个bias后，通过sigmoid层，将数值变到0到1的区间内，用于描述记住多少信息。</p>
<p>接下来我们需要对新的信息进行记忆，也就是记忆门：</p>
<p><img src="/2022/01/07/RNN/img-10.png" alt="img"></p>
<p> 为当前信息，我们需要挑选重要信息加入到 当中。tanh作用为激活函数。</p>
<p> 的作用类似于之前的  只是， 用来挑选  中记忆多少， 用来挑选当前记忆中记忆多少。</p>
<p> 与  相乘之后相当于重要的当前信息，然后加入到 当中。</p>
<p>这个时候获得的 就是当前的cell state 的完整信息。</p>
<p>下面则是控制输出：</p>
<p><img src="/2022/01/07/RNN/img-11.png" alt="img"></p>
<p> 用来选择哪些信息进行输出。</p>
<p>tanh 用来将结果压缩到 -1 到 1 之间。</p>
<p>输出。</p>
<h1><span id="variants-on-lstm">VARIANTS ON LSTM</span></h1><h2><span id="peephole-version">PEEPHOLE VERSION</span></h2><p>这种版本的主要特点是gate的输出也参考了cell state的信息。orginal version gate的输出只利用了当前状态和隐藏层信息。</p>
<p><img src="/2022/01/07/RNN/img-12.png" alt="img"></p>
<p>该示意图是所有的gate都融合了cell state的信息，但是许多论文只是部分gate融合cell state 信息。</p>
<h2><span id="shared-gate">SHARED GATE</span></h2><p>这种版本让forget gate 和 input gate 融合，使用相同的矩阵参数。</p>
<p><img src="/2022/01/07/RNN/img-13.png" alt="img"></p>
<p>也就是哪部分的信息被遗忘了，就用哪部分的的新信息来填补。</p>
<h2><span id="gru待补充">GRU(待补充)</span></h2><p>这种版本让隐藏层和cell state融合了：</p>
<p><img src="/2022/01/07/RNN/img-14.png" alt="img"></p>
<h1><span id="bilstm">BILSTM</span></h1><p><img src="/2022/01/07/RNN/img-15.png" alt="img"></p>
<p>双向LSTM只是用了两个LSTM，一个的句子从前向后输入，另一个从后向前输入。这种方法一定程度上融合了前后的信息。</p>
<p>两个LSTM，对应cell的输出（隐藏层）相互拼接的到结果。</p>
<h1><span id="transformer">TRANSFORMER</span></h1><p><strong>Motivation:</strong></p>
<ol>
<li>当前Cell state的计算依赖于前一个Cell state计算的结果，因此训练难以并行。</li>
<li>虽然LSTM一定程度上缓解了长期依赖问题，但是特长期问题仍然存在</li>
</ol>
<h2><span id="encoder">ENCODER</span></h2><p>当我们想去实现一个机器翻译的工作时候。</p>
<p>Seq2Seq的基本模型如下：</p>
<p><img src="/2022/01/07/RNN/transformer-1.png" alt="img"></p>
<p>其中的Encoder和Decoder都分别为一个RNN。</p>
<p>相比起 Seq2Seq 模型，Transformer的结构如下：（这个示例也是seq2seq形式的，在一些情况下，Transformer没有decoder这些部分）</p>
<p><img src="/2022/01/07/RNN/transformer-2.png" alt="img"></p>
<p>由多个Encoder 和多个Decoder堆叠而成。<del>之所以有这样的设计是因为我们希望翻译得到的每一个词都能有和它对应的原词。一个Encoder对应一个原本的word，一个decoder对应一个翻译的到word。</del></p>
<p>每一个Encoder对应内部结构如下：</p>
<p><img src="/2022/01/07/RNN/transformer-3.png" alt="img"></p>
<p>Encoder的输入先经过一个Self-Attention层，再经过一个Feed Forward Neural Network.</p>
<p><img src="/2022/01/07/RNN/transformer-1-1.png" alt="img"></p>
<p>需要注意的是单独的word做单独的Feed Forward Neural Network</p>
<h2><span id="self-attention">SELF-ATTENTION</span></h2><p>在这里的Self-Attention的作用在于让Encoder在Encode某个word的时候可以看到其他的word。</p>
<p>比如我们试图翻译如下句子：</p>
<p>”<code>The animal didn&#39;t cross the street because it was too tired</code>”</p>
<p>这里的it指代的是什么？相比起RNN的方式self-attention能让it和animal之间直接的联系起来。</p>
<p><img src="/2022/01/07/RNN/transformer-4.png" alt="img"></p>
<p>Transformer使用的是Multihead Self-Attention，但是这里先从原始Self-Attention开始。</p>
<p>接下来介绍原始Self-Attention的细节</p>
<p>正如所有的Attention机制一样，Self-Attention需要3个变量，Query vector，Key vector，Value vector</p>
<p>首先，这3个变量都是由Embedding乘各自的一个matrix获得的。需要注意的是，这3种vector的长度都要比Embedding短。</p>
<p><img src="/2022/01/07/RNN/transformer-5.png" alt="img"></p>
<p>其中 以此类推。</p>
<p>接下来，由于self-Attention 需要让每两个word之间都有连接。因此，假如句子为 “Thinking Machines” 则对于word - “Thinking” ,它的query  需要和 以及 进行点积。</p>
<p>由于我们想要获得的是weight，因此对[, ]进行softmax操作，得到[, ]。显然  会更大，通过这种方式大部分的weight仍然在本个单词上，但会有少量的weight分布在其他的word上。</p>
<p>对values进行weighted sum，得到的  为Thinking的Self-Attention的输出。</p>
<p>Multi-headed Self-Attention</p>
<p>多头自注意力机制相比于self-attention有多组用来得到Query，Key，Value的matrix。</p>
<p>比如有8个head，则有8套matrix。对于词 Thinking 得到8个self-attention输出的matrix。</p>
<p>为了整合信息，将8个matrix进行拼接，并乘以一个wighted matrix  , 得到Multi-headed Self-Attention 的结果。</p>
<p>流程如下：</p>
<p><img src="/2022/01/07/RNN/transformer-6.png" alt="img"></p>
<p><img src="/2022/01/07/RNN/transformer-7.png" alt="img"></p>
<h2><span id="residuals">RESIDUALS</span></h2><p>由于word的位置有时也会影响对句子的理解，因此word的embedding需要加入位置信息，这种位置信息可以直接反应两个word之间的distance，将原有embedding与postion embedding（由定义的三角函数获得，并非训练得到）相加得到最终embedding。</p>
<p>需要注意的是，计算的key，value，query，使用的是加入了position embedding的。</p>
<p>另外每一层self-attention, 每一层的Feed Forward Neural Network后都加了一层normalization layer。</p>
<p>做法是将对应normalization层前一层的输入和输出相加后进行normalization。如下图所示：</p>
<p><img src="/2022/01/07/RNN/transformer-8.png" alt="img"></p>
<h2><span id="decoder">DECODER</span></h2><p>完整的Transformer结构如下（此为Encoder和Decoder都是2个的情况）：</p>
<p><img src="/2022/01/07/RNN/transformer-9.png" alt="img"></p>
<h1><span id="self-regression">Self Regression</span></h1><p>之前的模型可以有多种应用。如果应用到文本的生成，一般采用自回归的方法。</p>
<p>也就是：</p>
<ul>
<li>训练时，每一个cell输入是ground truth中的前一个词。cell的输出和ground truth计算损失，做更新。</li>
<li>生成时，每一个cell的输入是前一个生成的词。持续生成直到生成终止符号。</li>
</ul>

      </section>

      
      
        <nav class="article-nav">
          
          
            <div class="article-nav-item layout-padding">
  <article class="card-container article-nav-card content-padding--primary soft-size--large soft-style--box">
    
    <div class="card-text">
      
        <a href="/2022/01/07/hello-world/" itemprop="url">
          <h2 class="card-text--title text-ellipsis">Hello World</h2>
        </a>
      
      <div class="card-text--row">Older</div>
    </div>
  </article>
</div>
          
        </nav>
      

      <section class="page-message-container layout-padding">
        


  
  

  
  


      </section>
    </div>
    <div class="widget-info">
      <section class="widget-author widget-item layout-margin content-padding--primary soft-size--large soft-style--box">
  <div class="widget-body">
    
      <img src="https://tse1-mm.cn.bing.net/th/id/R-C.29c8996da1bf1f48ea6cc1acdd6ddc73?rik=rKu4rq3p%2fhq2fw&amp;riu=http%3a%2f%2fimg.jj20.com%2fup%2fallimg%2ftx04%2f071020196281.jpg&amp;ehk=3Y6nuhq9WHChmrKaH01Pi6AwbKA8q873dcDJklJw028%3d&amp;risl=&amp;pid=ImgRaw&amp;r=0&amp;sres=1&amp;sresct=1" class="soft-size--round soft-style--box" alt="Han">
    
    
      <h2>Han</h2>
    
    
      <p>????</p>
    

    <div class="count-box">
      <div class="count-box--item">
        <svg class="icon icon-article" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M240.51564747 647.74217627h196.07203239c16.59071043 0 30.16492806-13.57421762 30.16492805-30.16492806V165.10332731c0-33.18142087-30.16492806-60.32985613-60.32985612-60.32985611H245.04038668C225.43318342 104.7734712 210.35071939 119.85593522 210.35071939 139.46313845V617.57724821c0 16.59071043 13.57421762 30.16492806 30.16492808 30.16492806z m663.62841731-452.47392089v482.63884894c0 33.18142087-27.14843525 60.32985613-60.32985612 60.32985613H180.18579134c-33.18142087 0-60.32985613-27.14843525-60.32985612-60.32985613V195.26825538c-49.77213131 0-90.49478418 40.72265287-90.49478417 90.49478417v452.4739209c0 49.77213131 40.72265287 90.49478418 90.49478417 90.49478417h286.56681657c16.59071043 0 30.16492806 13.57421762 30.16492807 30.16492807s13.57421762 30.16492806 30.16492805 30.16492806h90.49478418c16.59071043 0 30.16492806-13.57421762 30.16492805-30.16492806s13.57421762-30.16492806 30.16492807-30.16492807h286.56681657c49.77213131 0 90.49478418-40.72265287 90.49478417-90.49478417V285.76303955c0-49.77213131-40.72265287-90.49478418-90.49478417-90.49478417zM587.41232014 647.74217627h191.54729318c19.60720323 0 34.68966726-15.08246403 34.68966729-34.68966727V134.93839925c0-16.59071043-13.57421762-30.16492806-30.16492808-30.16492805H617.57724821c-30.16492806 0-60.32985613 27.14843525-60.32985612 60.32985611v452.4739209c0 16.59071043 13.57421762 30.16492806 30.16492805 30.16492806z" fill="currentColor"></path>
</svg>
        <span>2</span>
      </div>
      <div class="count-box--item">
        <svg class="icon icon-categories" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M900.3614811 257.09082106h-339.81629553l-67.96326003-101.9448889c-19.41807444-29.12711113-48.54518557-43.69066667-82.52681443-43.69066667H123.6385189c-53.39970333 0-97.09036999 43.69066667-97.09037113 97.09036999v582.54222222c0 53.39970333 43.69066667 97.09036999 97.09037113 97.09037002h776.7229622c53.39970333 0 97.09036999-43.69066667 97.09037113-97.09037002V354.18119104c0-53.39970333-43.69066667-97.09036999-97.09037113-97.09036998z m-97.09036999 242.72592554H220.72888889c-24.27259221 0-48.54518557-24.27259221-48.54518556-48.54518556s24.27259221-48.54518557 48.54518556-48.54518444h582.54222222c24.27259221 0 48.54518557 24.27259221 48.54518556 48.54518444s-24.27259221 48.54518557-48.54518556 48.54518556z" fill="currentColor"></path>
</svg>
        2
      </div>
      <div class="count-box--item">
        <svg class="icon icon-tags" viewBox="0 0 1098 1024" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M283.42180005 272q0-28.38857157-20.09142843-48.48000001t-48.47999998-20.09142842-48.48000002 20.09142842-20.09142846 48.48000001 20.09142846 48.48 48.48000002 20.09142843 48.47999998-20.09142843 20.09142843-48.48zM855.0332285 580.57142843q0 28.38857157-19.81714313 48.2057147l-263.03999997 263.58857157q-20.9142853 19.81714313-48.75428534 19.81714312-28.38857157 0-48.20571468-19.81714312l-383.04-383.58857157q-20.36571468-19.81714313-34.55999999-54.10285688t-14.19428534-62.6742853l0-222.85714313q0-27.84000002 20.36571469-48.20571469t48.2057147-20.36571466l222.85714313 0q28.38857157 0 62.6742853 14.19428529t54.65142842 34.55999999l383.04000001 382.49142843q19.81714313 20.9142853 19.81714314 48.75428532zM1060.74751475 580.57142843q0 28.38857157-19.81714313 48.2057147l-263.04 263.58857157q-20.9142853 19.81714313-48.75428531 19.81714312-19.26857155 0-31.61142843-7.47428531t-28.38857159-24.13714314l251.79428534-251.7942853q19.81714313-19.81714313 19.81714308-48.20571469 0-27.84000002-19.81714308-48.75428531l-383.04000001-382.49142845q-20.36571468-20.36571468-54.65142842-34.55999999t-62.67428532-14.19428534l120 0q28.38857157 0 62.67428532 14.19428534t54.65142842 34.55999999l383.03999998 382.49142845q19.81714313 20.9142853 19.81714314 48.75428531z" fill="currentColor"></path>
</svg>
        1
      </div>
    </div>
  </div>
</section>

      

      
<section class="widet-notice widget-item layout-margin content-padding--primary soft-size--large soft-style--box">
  <div class="widget-title">
    <svg class="icon icon-notice" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M512 945.02305225v28.15620663a24.27259221 24.27259221 0 0 1-24.27259221 24.27259335H394.0352a48.54518557 48.54518557 0 0 1-41.74885888-23.78714112l-110.68302222-184.47170332a132.04290333 132.04290333 0 0 1-17.47626667-48.54518557h118.4502511a200.97706667 200.97706667 0 0 1 76.21594113 14.56355556l20.38897777 133.49925888a48.54518557 48.54518557 0 0 0 36.40888888 27.67075555l16.01991111 2.91271112a24.27259221 24.27259221 0 0 1 20.38897778 25.72894889zM997.45185223 463.45481443a194.18074112 194.18074112 0 0 1-38.8361489 116.50844445 24.75804445 24.75804445 0 0 1-36.4088889 0l-34.95253333-34.95253333a24.27259221 24.27259221 0 0 1-2.91271111-30.58346667 97.09036999 97.09036999 0 0 0 0-106.79940665 24.27259221 24.27259221 0 0 1 2.91271111-30.58346666l34.95253333-34.95253334a24.75804445 24.75804445 0 0 1 18.93262223-7.28177777 26.2144 26.2144 0 0 1 17.47626667 9.70903665A194.18074112 194.18074112 0 0 1 997.45185223 463.45481443z m-194.18074112-388.36148111v776.72296335a48.54518557 48.54518557 0 0 1-48.54518556 48.54518443h-28.64165888a48.54518557 48.54518557 0 0 1-33.98163001-14.07810332l-145.63555556-143.20829668A291.27111111 291.27111111 0 0 0 342.57730333 657.63555556H172.18370333a145.63555556 145.63555556 0 0 1-145.63555556-145.63555556v-97.09036999a145.63555556 145.63555556 0 0 1 145.63555556-145.63555556h170.3936a291.27111111 291.27111111 0 0 0 206.31703779-85.43952668l145.63555555-143.20829554a48.54518557 48.54518557 0 0 1 33.98162888-14.07810446H754.72592555a48.54518557 48.54518557 0 0 1 48.54518556 48.54518555z" fill="currentColor"></path>
</svg>
    <span>NOTICE</span>
  </div>
  <div class="widget-body">
    <p>flex-block主题部分重构，详情查看https://github.com/miiiku/flex-block</p>
  </div>
</section>


      <section class="widget-categorys widget-item layout-margin content-padding--primary soft-size--large soft-style--box">
  <div class="widget-title">
    <svg class="icon icon-categories" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M900.3614811 257.09082106h-339.81629553l-67.96326003-101.9448889c-19.41807444-29.12711113-48.54518557-43.69066667-82.52681443-43.69066667H123.6385189c-53.39970333 0-97.09036999 43.69066667-97.09037113 97.09036999v582.54222222c0 53.39970333 43.69066667 97.09036999 97.09037113 97.09037002h776.7229622c53.39970333 0 97.09036999-43.69066667 97.09037113-97.09037002V354.18119104c0-53.39970333-43.69066667-97.09036999-97.09037113-97.09036998z m-97.09036999 242.72592554H220.72888889c-24.27259221 0-48.54518557-24.27259221-48.54518556-48.54518556s24.27259221-48.54518557 48.54518556-48.54518444h582.54222222c24.27259221 0 48.54518557 24.27259221 48.54518556 48.54518444s-24.27259221 48.54518557-48.54518556 48.54518556z" fill="currentColor"></path>
</svg>
    <span>CATEGORYS</span>
  </div>
  <div class="widget-body">
    <ul class="categorys-list">
      
        <li class="categorys-list-item">
          <a href="/categories/other/">
            other (1)
          </a>
        </li>
      
        <li class="categorys-list-item">
          <a href="/categories/BasicModels/">
            BasicModels (1)
          </a>
        </li>
      
    </ul>
  </div>
</section>

      <section class="widget-tags widget-item  layout-margin content-padding--primary soft-size--large soft-style--box">
  <div class="widget-title">
    <svg class="icon icon-tags" viewBox="0 0 1098 1024" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M283.42180005 272q0-28.38857157-20.09142843-48.48000001t-48.47999998-20.09142842-48.48000002 20.09142842-20.09142846 48.48000001 20.09142846 48.48 48.48000002 20.09142843 48.47999998-20.09142843 20.09142843-48.48zM855.0332285 580.57142843q0 28.38857157-19.81714313 48.2057147l-263.03999997 263.58857157q-20.9142853 19.81714313-48.75428534 19.81714312-28.38857157 0-48.20571468-19.81714312l-383.04-383.58857157q-20.36571468-19.81714313-34.55999999-54.10285688t-14.19428534-62.6742853l0-222.85714313q0-27.84000002 20.36571469-48.20571469t48.2057147-20.36571466l222.85714313 0q28.38857157 0 62.6742853 14.19428529t54.65142842 34.55999999l383.04000001 382.49142843q19.81714313 20.9142853 19.81714314 48.75428532zM1060.74751475 580.57142843q0 28.38857157-19.81714313 48.2057147l-263.04 263.58857157q-20.9142853 19.81714313-48.75428531 19.81714312-19.26857155 0-31.61142843-7.47428531t-28.38857159-24.13714314l251.79428534-251.7942853q19.81714313-19.81714313 19.81714308-48.20571469 0-27.84000002-19.81714308-48.75428531l-383.04000001-382.49142845q-20.36571468-20.36571468-54.65142842-34.55999999t-62.67428532-14.19428534l120 0q28.38857157 0 62.67428532 14.19428534t54.65142842 34.55999999l383.03999998 382.49142845q19.81714313 20.9142853 19.81714314 48.75428531z" fill="currentColor"></path>
</svg>
    <span>TAGS</span>
  </div>
  <div class="widget-body">
    <div class="tags-cloud">
      <a href="/tags/basic/" style="font-size: 10px;" class="tags-cloud-0">basic</a>
    </div>
  </div>
</section>
    </div>
  </article>
</div>

    <!-- footer container -->
<footer id="footer" class="footer">
  <div class="footer-container">
    
    <div class="social-icons">
      
        
      
        
      
        
      
        
          <a href="https://github.com/miiiku/" class="soft-size--primary soft-style--box" target="_blank" rel="noopener noreferrer">
            <svg class="icon icon-github" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M64.6 512c0 195.6 125.4 361.9 300.1 422.9 23.5 5.9 19.9-10.8 19.9-22.2v-77.6c-135.8 15.9-141.3-74-150.5-89-18.5-31.5-61.9-39.5-49-54.5 31-15.9 62.5 4 98.9 58 26.4 39.1 77.9 32.5 104.1 26 5.7-23.5 17.9-44.5 34.7-60.9-140.7-25.2-199.4-111.1-199.4-213.3 0-49.5 16.4-95.1 48.4-131.8-20.4-60.6 1.9-112.4 4.9-120.1 58.2-5.2 118.5 41.6 123.3 45.3 33.1-8.9 70.8-13.7 112.9-13.7 42.4 0 80.3 4.9 113.5 13.9 11.3-8.6 67.3-48.8 121.4-43.9 2.9 7.7 24.7 58.3 5.5 118.1 32.5 36.8 49 82.8 49 132.4 0 102.3-59 188.3-200.2 213.2 23.5 23.3 38.1 55.5 38.1 91.1v112.7c0.8 9 0 17.9 15.1 17.9C832.7 877 960.4 709.4 960.4 512.1c0-247.5-200.6-447.9-447.9-447.9C265 64.1 64.6 264.5 64.6 512z"></path>
</svg>
          </a>
        
      
        
          <a href="https://twitter.com/guanquanhong" class="soft-size--primary soft-style--box" target="_blank" rel="noopener noreferrer">
            <svg class="icon icon-twitter" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M962.285714 233.142857q-38.285714 56-92.571429 95.428571 0.571429 8 0.571429 24 0 74.285714-21.714286 148.285714t-66 142-105.428571 120.285714-147.428571 83.428571-184.571429 31.142857q-154.857143 0-283.428571-82.857143 20 2.285714 44.571429 2.285714 128.571429 0 229.142857-78.857143-60-1.142857-107.428571-36.857143t-65.142857-91.142857q18.857143 2.857143 34.857143 2.857143 24.571429 0 48.571429-6.285714-64-13.142857-106-63.714286t-42-117.428571l0-2.285714q38.857143 21.714286 83.428571 23.428571-37.714286-25.142857-60-65.714286t-22.285714-88q0-50.285714 25.142857-93.142857 69.142857 85.142857 168.285714 136.285714t212.285714 56.857143q-4.571429-21.714286-4.571429-42.285714 0-76.571429 54-130.571429t130.571429-54q80 0 134.857143 58.285714 62.285714-12 117.142857-44.571429-21.142857 65.714286-81.142857 101.714286 53.142857-5.714286 106.285714-28.571429z"></path>
</svg>
          </a>
        
      
    </div>
     
    <p>&copy; 2022 <a href="/" target="_blank">Han Yu</a></p>

    

    <p>Powered by <a href="https://hexo.io" target="_blank" rel="noopener noreferrer">Hexo</a> Theme - <a href="https://github.com/miiiku/flex-block" target="_blank" rel="noopener noreferrer author">flex-block</a></p>

    <p>
      <a href="javascript:;" id="theme-light">🌞 浅色</a>
      <a href="javascript:;" id="theme-dark">🌛 深色</a>
      <a href="javascript:;" id="theme-auto">🤖️ 自动</a>
    </p>
  </div>
</footer>
  </div>

  <div class="back-to-top-fixed soft-size--round soft-style--box">
    <svg class="icon icon-back-to-top" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg">
      <path d="M725.333333 426.666667c-12.8 0-21.333333-4.266667-29.866667-12.8l-213.333333-213.333333c-17.066667-17.066667-17.066667-42.666667 0-59.733333s42.666667-17.066667 59.733333 0l213.333333 213.333333c17.066667 17.066667 17.066667 42.666667 0 59.733333C746.666667 422.4 738.133333 426.666667 725.333333 426.666667z"></path>
      <path d="M298.666667 426.666667c-12.8 0-21.333333-4.266667-29.866667-12.8-17.066667-17.066667-17.066667-42.666667 0-59.733333l213.333333-213.333333c17.066667-17.066667 42.666667-17.066667 59.733333 0s17.066667 42.666667 0 59.733333l-213.333333 213.333333C320 422.4 311.466667 426.666667 298.666667 426.666667z"></path>
      <path d="M512 896c-25.6 0-42.666667-17.066667-42.666667-42.666667L469.333333 170.666667c0-25.6 17.066667-42.666667 42.666667-42.666667s42.666667 17.066667 42.666667 42.666667l0 682.666667C554.666667 878.933333 537.6 896 512 896z"></path>
    </svg>
  </div>

  
  <!-- aplayer -->


<!-- dplayer -->




  


  


  




<script src="/js/script.js"></script>


  
  <!-- 尾部用户自定义相关内容 -->
</body>
</html>